{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FXcnXniIXRp"
      },
      "outputs": [],
      "source": [
        "!pip install muax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxpr4KvuIXRt"
      },
      "outputs": [],
      "source": [
        "import jax \n",
        "jax.config.update('jax_platform_name', 'cpu')\n",
        "\n",
        "import gymnasium as gym "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdV2IbCGIXRu"
      },
      "source": [
        "# 1. Use `muax.fit` to fit CartPole-v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGFX2OcGIXRv"
      },
      "outputs": [],
      "source": [
        "import muax\n",
        "from muax import nn "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x4CU6COIXRw"
      },
      "source": [
        "`muax` provides example `representation`, `prediction` and `dynamic` modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3G0w2qUIXRw"
      },
      "outputs": [],
      "source": [
        "support_size = 10 \n",
        "embedding_size = 8\n",
        "discount = 0.997\n",
        "num_actions = 2\n",
        "full_support_size = int(support_size * 2 + 1)\n",
        "\n",
        "repr_fn = nn._init_representation_func(nn.Representation, embedding_size)\n",
        "pred_fn = nn._init_prediction_func(nn.Prediction, num_actions, full_support_size)\n",
        "dy_fn = nn._init_dynamic_func(nn.Dynamic, embedding_size, num_actions, full_support_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHBV0UXFIXRw"
      },
      "source": [
        "Alternatively, you can use your customized models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBv5cAgZIXRx"
      },
      "outputs": [],
      "source": [
        "from jax import numpy as jnp \n",
        "import haiku as hk\n",
        "\n",
        "\n",
        "class Representation(hk.Module):\n",
        "  def __init__(self, embedding_dim, name='representation'):\n",
        "    super().__init__(name=name)\n",
        "\n",
        "    self.repr_func = hk.Sequential([\n",
        "        hk.Linear(embedding_dim)\n",
        "    ])\n",
        "\n",
        "  def __call__(self, obs):\n",
        "    s = self.repr_func(obs)\n",
        "    return s \n",
        "\n",
        "\n",
        "class Prediction(hk.Module):\n",
        "  def __init__(self, num_actions, full_support_size, name='prediction'):\n",
        "    super().__init__(name=name)        \n",
        "    \n",
        "    self.v_func = hk.Sequential([\n",
        "        hk.Linear(16), jax.nn.elu,\n",
        "        hk.Linear(full_support_size)\n",
        "    ])\n",
        "    self.pi_func = hk.Sequential([\n",
        "        hk.Linear(16), jax.nn.elu,\n",
        "        hk.Linear(num_actions)\n",
        "    ])\n",
        "  \n",
        "  def __call__(self, s):\n",
        "    v = self.v_func(s)\n",
        "    logits = self.pi_func(s)\n",
        "    logits = jax.nn.softmax(logits, axis=-1)\n",
        "    return v, logits\n",
        "\n",
        "\n",
        "class Dynamic(hk.Module):\n",
        "  def __init__(self, embedding_dim, num_actions, full_support_size, name='dynamic'):\n",
        "    super().__init__(name=name)\n",
        "    \n",
        "    self.ns_func = hk.Sequential([\n",
        "        hk.Linear(16), jax.nn.elu,\n",
        "        hk.Linear(embedding_dim)\n",
        "    ])\n",
        "    self.r_func = hk.Sequential([\n",
        "        hk.Linear(16), jax.nn.elu,\n",
        "        hk.Linear(full_support_size)\n",
        "    ])\n",
        "    self.cat_func = jax.jit(lambda s, a: \n",
        "                            jnp.concatenate([s, jax.nn.one_hot(a, num_actions)],\n",
        "                                            axis=1)\n",
        "                            )\n",
        "  \n",
        "  def __call__(self, s, a):\n",
        "    sa = self.cat_func(s, a)\n",
        "    r = self.r_func(sa)\n",
        "    ns = self.ns_func(sa)\n",
        "    return r, ns\n",
        "\n",
        "\n",
        "def init_representation_func(representation_module, embedding_dim):\n",
        "    def representation_func(obs):\n",
        "      repr_model = representation_module(embedding_dim)\n",
        "      return repr_model(obs)\n",
        "    return representation_func\n",
        "  \n",
        "def init_prediction_func(prediction_module, num_actions, full_support_size):\n",
        "  def prediction_func(s):\n",
        "    pred_model = prediction_module(num_actions, full_support_size)\n",
        "    return pred_model(s)\n",
        "  return prediction_func\n",
        "\n",
        "def init_dynamic_func(dynamic_module, embedding_dim, num_actions, full_support_size):\n",
        "  def dynamic_func(s, a):\n",
        "    dy_model = dynamic_module(embedding_dim, num_actions, full_support_size)\n",
        "    return dy_model(s, a)\n",
        "  return dynamic_func \n",
        "\n",
        "repr_fn = init_representation_func(Representation, embedding_size)\n",
        "pred_fn = init_prediction_func(Prediction, 2, full_support_size)\n",
        "dy_fn = init_dynamic_func(Dynamic, embedding_size, 2, full_support_size)  \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUxabY7zIXRy"
      },
      "source": [
        "`muax` has `Episode tracer` and `replay buffuer` to track and store trajectories from interacting with environments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhQ3hQGCIXRy"
      },
      "outputs": [],
      "source": [
        "tracer = muax.PNStep(10, discount, 0.5)\n",
        "buffer = muax.TrajectoryReplayBuffer(500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_Tj7snvIXRz"
      },
      "source": [
        "`muax` leverages `optax` to update weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Llw8cpKvIXRz"
      },
      "outputs": [],
      "source": [
        "gradient_transform = muax.model.optimizer(init_value=0.02, peak_value=0.02, end_value=0.0001, warmup_steps=15000, transition_steps=15000)\n",
        "# gradient_transform = optax.adam(0.02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6pbRyK1IXRz"
      },
      "outputs": [],
      "source": [
        "model = muax.MuZero(repr_fn, pred_fn, dy_fn, policy='muzero', discount=discount,\n",
        "                    optimizer=gradient_transform, support_size=support_size)\n",
        "\n",
        "model_path = muax.fit(model, 'CartPole-v1', \n",
        "                    max_episodes=1000,\n",
        "                    max_training_steps=30000,\n",
        "                    test_interval=10,\n",
        "                    save_every_n_epochs=1,\n",
        "                    tracer=tracer,\n",
        "                    buffer=buffer,\n",
        "                    k_steps=10,\n",
        "                    sample_per_trajectory=1,\n",
        "                    num_trajectory=32,\n",
        "                    tensorboard_dir='/content/tensorboard/cartpole',\n",
        "                    model_save_path='/content/models/cartpole',\n",
        "                    save_name='cartpole_model_params',\n",
        "                    random_seed=0,\n",
        "                    log_all_metrics=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4tJqp3rIXR0"
      },
      "outputs": [],
      "source": [
        "model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ev9Wh1mwIXR0"
      },
      "outputs": [],
      "source": [
        "model = muax.MuZero(repr_fn, pred_fn, dy_fn, policy='muzero', discount=discount,\n",
        "                    optimizer=gradient_transform, support_size=support_size)\n",
        "\n",
        "model.load(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsvTLhtCIXR0"
      },
      "outputs": [],
      "source": [
        "from muax.test import test\n",
        "env_id = 'CartPole-v1'\n",
        "test_env = gym.make(env_id, render_mode='rgb_array')\n",
        "test_key = jax.random.PRNGKey(0)\n",
        "test(model, test_env, test_key, num_simulations=50, num_test_episodes=100, random_seed=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard \n",
        "%tensorboard --logdir=tensorboard/cartpole"
      ],
      "metadata": {
        "id": "Vjf4pWmbVKmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1EkABpZIXR0"
      },
      "source": [
        "# 2. Customize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDcb8qM-IXR0"
      },
      "source": [
        "## 2.1 Customize the neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgRLKasVIXR0"
      },
      "source": [
        "`muax` uses `haiku` to implement the neural networks. A tutorial for using `haiku` can be found at (link). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8sDcuJ2IXR1"
      },
      "outputs": [],
      "source": [
        "from jax import numpy as jnp \n",
        "import haiku as hk\n",
        "\n",
        "\n",
        "class Representation(hk.Module):\n",
        "  def __init__(self, embedding_dim, name='representation'):\n",
        "    super().__init__(name=name)\n",
        "\n",
        "    self.repr_func = hk.Sequential([\n",
        "        hk.Linear(embedding_dim), jax.nn.elu\n",
        "    ])\n",
        "\n",
        "  def __call__(self, obs):\n",
        "    s = self.repr_func(obs)\n",
        "    return s \n",
        "\n",
        "\n",
        "class Prediction(hk.Module):\n",
        "  def __init__(self, num_actions, full_support_size, name='prediction'):\n",
        "    super().__init__(name=name)        \n",
        "    \n",
        "    self.v_func = hk.Sequential([\n",
        "        hk.Linear(16), jax.nn.elu,\n",
        "        hk.Linear(full_support_size)\n",
        "    ])\n",
        "    self.pi_func = hk.Sequential([\n",
        "        hk.Linear(16), jax.nn.elu,\n",
        "        hk.Linear(num_actions)\n",
        "    ])\n",
        "  \n",
        "  def __call__(self, s):\n",
        "    v = self.v_func(s)\n",
        "    logits = self.pi_func(s)\n",
        "    logits = jax.nn.softmax(logits, axis=-1)\n",
        "    return v, logits\n",
        "\n",
        "\n",
        "class Dynamic(hk.Module):\n",
        "  def __init__(self, embedding_dim, num_actions, full_support_size, name='dynamic'):\n",
        "    super().__init__(name=name)\n",
        "    \n",
        "    self.ns_func = hk.Sequential([\n",
        "        hk.Linear(16), jax.nn.elu,\n",
        "        hk.Linear(embedding_dim)\n",
        "    ])\n",
        "    self.r_func = hk.Sequential([\n",
        "        hk.Linear(16), jax.nn.elu,\n",
        "        hk.Linear(full_support_size)\n",
        "    ])\n",
        "    self.cat_func = jax.jit(lambda s, a: \n",
        "                            jnp.concatenate([s, jax.nn.one_hot(a, num_actions)],\n",
        "                                            axis=1)\n",
        "                            )\n",
        "  \n",
        "  def __call__(self, s, a):\n",
        "    sa = self.cat_func(s, a)\n",
        "    r = self.r_func(sa)\n",
        "    ns = self.ns_func(sa)\n",
        "    return r, ns\n",
        "\n",
        "\n",
        "def init_representation_func(representation_module, embedding_dim):\n",
        "    def representation_func(obs):\n",
        "      repr_model = representation_module(embedding_dim)\n",
        "      return repr_model(obs)\n",
        "    return representation_func\n",
        "  \n",
        "def init_prediction_func(prediction_module, num_actions, full_support_size):\n",
        "  def prediction_func(s):\n",
        "    pred_model = prediction_module(num_actions, full_support_size)\n",
        "    return pred_model(s)\n",
        "  return prediction_func\n",
        "\n",
        "def init_dynamic_func(dynamic_module, embedding_dim, num_actions, full_support_size):\n",
        "  def dynamic_func(s, a):\n",
        "    dy_model = dynamic_module(embedding_dim, num_actions, full_support_size)\n",
        "    return dy_model(s, a)\n",
        "  return dynamic_func \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHpJLiCgIXR1"
      },
      "outputs": [],
      "source": [
        "support_size = 10 \n",
        "embedding_size = 8\n",
        "full_support_size = int(support_size * 2 + 1)\n",
        "repr_fn = init_representation_func(Representation, embedding_size)\n",
        "pred_fn = init_prediction_func(Prediction, 2, full_support_size)\n",
        "dy_fn = init_dynamic_func(Dynamic, embedding_size, 2, full_support_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85ez-RWWIXR1"
      },
      "source": [
        "## 2.2 Customize the training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR5bvL2ZIXR1"
      },
      "source": [
        "inside the `muax.fit` function, the main structure is a typical RL interacting loop. Reset the env, agent takes an action based on the observation, updated current state until done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvenwlWaIXR1"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "from muax import Trajectory\n",
        "\n",
        "def temperature_fn(max_training_steps, training_steps):\n",
        "  if training_steps < 0.5 * max_training_steps:\n",
        "      return 1.0\n",
        "  elif training_steps < 0.75 * max_training_steps:\n",
        "      return 0.5\n",
        "  else:\n",
        "      return 0.25\n",
        "  \n",
        "def test(model, env, key, num_simulations, num_test_episodes=10, random_seed=None):\n",
        "    total_rewards = np.zeros(num_test_episodes)\n",
        "    for episode in range(num_test_episodes):\n",
        "        obs, info = env.reset(seed=random_seed)\n",
        "        done = False\n",
        "        episode_reward = 0\n",
        "        for t in range(env.spec.max_episode_steps):\n",
        "            key, subkey = jax.random.split(key)\n",
        "            a = model.act(subkey, obs, \n",
        "                          with_pi=False, \n",
        "                          with_value=False, \n",
        "                          obs_from_batch=False,\n",
        "                          num_simulations=num_simulations,\n",
        "                          temperature=0.) # Use deterministic actions during testing\n",
        "            obs_next, r, done, truncated, info = env.step(a)\n",
        "            episode_reward += r\n",
        "            if done or truncated:\n",
        "                break \n",
        "            obs = obs_next \n",
        "        \n",
        "        total_rewards[episode] = episode_reward\n",
        "\n",
        "    average_test_reward = np.mean(total_rewards)\n",
        "    return average_test_reward  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWxYu6McIXR1"
      },
      "outputs": [],
      "source": [
        "random_seed = 0\n",
        "discount = 0.997\n",
        "buffer_warm_up = 64\n",
        "max_training_steps = 10000\n",
        "max_episodes = 1000\n",
        "num_simulations = 50\n",
        "num_test_episodes = 10\n",
        "num_trajectory = 32\n",
        "sample_per_trajectory = 1\n",
        "k_steps = 10\n",
        "\n",
        "gradient_transform = muax.model.optimizer(init_value=0.02, peak_value=0.02, end_value=0.002, warmup_steps=5000, transition_steps=5000)\n",
        "tracer = muax.PNStep(10, discount, 0.5)\n",
        "buffer = muax.TrajectoryReplayBuffer(500)\n",
        "model = muax.MuZero(repr_fn, pred_fn, dy_fn, optimizer=gradient_transform, discount=discount)\n",
        "\n",
        "env_id = 'CartPole-v1'\n",
        "env = gym.make(env_id, render_mode='rgb_array')\n",
        "test_env = gym.make(env_id, render_mode='rgb_array')\n",
        "\n",
        "sample_input = jnp.expand_dims(jnp.zeros(env.observation_space.shape), axis=0)\n",
        "key = jax.random.PRNGKey(random_seed)\n",
        "key, test_key, subkey = jax.random.split(key, num=3)\n",
        "model.init(subkey, sample_input) \n",
        "\n",
        "training_step = 0\n",
        "best_test_G = -float('inf')\n",
        "max_training_steps_reached = False\n",
        "\n",
        "# buffer warm up\n",
        "print('buffer warm up stage...')\n",
        "while len(buffer) < buffer_warm_up:\n",
        "  obs, info = env.reset()    \n",
        "  trajectory = Trajectory()\n",
        "  temperature = temperature_fn(max_training_steps=max_training_steps, training_steps=training_step)\n",
        "  for t in range(env.spec.max_episode_steps):\n",
        "    key, subkey = jax.random.split(key)\n",
        "    a, pi, v = model.act(subkey, obs, \n",
        "                          with_pi=True, \n",
        "                          with_value=True, \n",
        "                          obs_from_batch=False,\n",
        "                          num_simulations=num_simulations,\n",
        "                          temperature=temperature)\n",
        "    obs_next, r, done, truncated, info = env.step(a)\n",
        "    if truncated:\n",
        "      r = 1 / (1 - tracer.gamma)\n",
        "    tracer.add(obs, a, r, done or truncated, v=v, pi=pi)\n",
        "    while tracer:\n",
        "      trans = tracer.pop()\n",
        "      trajectory.add(trans)\n",
        "    if done or truncated:\n",
        "      break \n",
        "    obs = obs_next \n",
        "  trajectory.finalize()\n",
        "  if len(trajectory) >= k_steps:\n",
        "    buffer.add(trajectory, trajectory.batched_transitions.w.mean())\n",
        "  \n",
        "print('start training...')\n",
        "  \n",
        "for ep in range(max_episodes):\n",
        "  obs, info = env.reset(seed=random_seed)    \n",
        "  trajectory = Trajectory()\n",
        "  temperature = temperature_fn(max_training_steps=max_training_steps, training_steps=training_step)\n",
        "  for t in range(env.spec.max_episode_steps):\n",
        "    key, subkey = jax.random.split(key)\n",
        "    a, pi, v = model.act(subkey, obs, \n",
        "                          with_pi=True, \n",
        "                          with_value=True, \n",
        "                          obs_from_batch=False,\n",
        "                          num_simulations=num_simulations,\n",
        "                          temperature=temperature)\n",
        "    obs_next, r, done, truncated, info = env.step(a)\n",
        "    if truncated:\n",
        "      r = 1 / (1 - tracer.gamma)\n",
        "    tracer.add(obs, a, r, done or truncated, v=v, pi=pi)\n",
        "    while tracer:\n",
        "      trans = tracer.pop()\n",
        "      trajectory.add(trans)\n",
        "    if done or truncated:\n",
        "      break \n",
        "    obs = obs_next \n",
        "  trajectory.finalize()\n",
        "  if len(trajectory) >= k_steps:\n",
        "    buffer.add(trajectory, trajectory.batched_transitions.w.mean())\n",
        "  \n",
        "  if max_training_steps_reached:\n",
        "    break\n",
        "  train_loss = 0\n",
        "  for _ in range(t):\n",
        "    transition_batch = buffer.sample(num_trajectory=num_trajectory,\n",
        "                                      sample_per_trajectory=sample_per_trajectory,\n",
        "                                      k_steps=k_steps)\n",
        "    loss_metric = model.update(transition_batch)\n",
        "    train_loss += loss_metric['loss']\n",
        "    training_step += 1\n",
        "    if training_step >= max_training_steps:\n",
        "      max_training_steps_reached = True\n",
        "      break\n",
        "  train_loss /= t\n",
        "  print(f'epoch: {ep:04d}, loss: {train_loss:.8f}, training_step: {training_step}')\n",
        "\n",
        "  test_G = test(model, test_env, test_key, num_simulations=num_simulations, num_test_episodes=num_test_episodes)      \n",
        "  print(f'epoch: {ep:04d}, test_G: {test_G:.8f}')\n",
        "  if test_G >= best_test_G:\n",
        "    best_test_G = test_G\n",
        "\n",
        "print(f'Best total reward in test: {best_test_G}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IPJkGx0IXR2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}